{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqOtHMWIjtkY"
   },
   "source": [
    "## Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show(*img):\n",
    "    \n",
    "    if len(img)<2:\n",
    "        show_one(img[0])\n",
    "        return\n",
    "              \n",
    "    fig, axes = plt.subplots(1, len(img))\n",
    "    \n",
    "    for img_i, i in zip(img, range(len(img))):\n",
    "        axes[i].imshow(img_i, cmap='gray')\n",
    "        axes[i].set_title('')\n",
    "\n",
    "    fig.set_figwidth(20)    #  ширина и\n",
    "    fig.set_figheight(10)    #  высота \\\"Figure\\\n",
    "\n",
    "#     plt.gray()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_one(img, n = 10):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figwidth(n)    #  ширина и\n",
    "    fig.set_figheight(n)    #  высота \\\"Figure\\\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZZAvptc4Er-"
   },
   "source": [
    "## Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JhKSrA59m6H5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah58_q4n1Kpx"
   },
   "outputs": [],
   "source": [
    "def crop(frame):\n",
    "    return frame[850:1750, 0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRaceYCUQSt-"
   },
   "outputs": [],
   "source": [
    "def preprocessing(frame):\n",
    "    frame = frame.copy()\n",
    "    frame = cv2.GaussianBlur(frame, (15, 15), 0)\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v = cv2.equalizeHist(v)\n",
    "    hsv = cv2.merge([h, s, v])\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    return bgr, gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSobel(v):\n",
    "    scale = 1\n",
    "    delta = 0\n",
    "    ddepth = cv2.CV_16S\n",
    "    grad_x = cv2.Sobel(v, ddepth, 1, 0, ksize=5, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n",
    "    # Gradient-Y\n",
    "    grad_y = cv2.Scharr(v,ddepth,0,1)\n",
    "    grad_y = cv2.Sobel(v, ddepth, 0, 1, ksize=5, scale=scale, delta=delta, borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "    abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "    abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "    maskSobel = cv2.addWeighted(abs_grad_x, 0.5, abs_grad_y, 0.5, 0)\n",
    "    maskSobel = cv2.threshold(maskSobel, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "#     print('sobel')\n",
    "#     show(maskSobel)\n",
    "    return maskSobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMarkers(v):\n",
    "    kernel = np.ones((9, 9), np.uint8)\n",
    "    v = cv2.morphologyEx(v, cv2.MORPH_OPEN, kernel)\n",
    "    v = cv2.cvtColor(v, cv2.COLOR_GRAY2BGR)\n",
    "    v = cv2.pyrMeanShiftFiltering(v, 11, 21)\n",
    "    v = cv2.cvtColor(v, cv2.COLOR_BGR2GRAY)\n",
    "    homo_filter = HomomorphicFilter(a = 0.75, b = 1.25)\n",
    "    v = homo_filter.filter(I=v, filter_params=[20,2])\n",
    "#     print('before markers')\n",
    "#     show(v)\n",
    "#     thresh = cv2.adaptiveThreshold(v, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 2)\n",
    "    thresh = cv2.threshold(v,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "    markers = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    markers = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "#     print('markers')\n",
    "#     show(markers)\n",
    "    return thresh\n",
    "#     return markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzt2sJBTRClW"
   },
   "outputs": [],
   "source": [
    "def doWatershed(markers, maskSobel):\n",
    "    distance_map = ndimage.distance_transform_edt(markers)\n",
    "    local_max = peak_local_max(distance_map, indices=False, min_distance=10, labels=markers)\n",
    "#     print('local max')\n",
    "#     show(local_max)\n",
    "    # Perform connected component analysis then apply Watershed\n",
    "    markers = ndimage.label(local_max, structure=np.ones((3, 3)))[0]\n",
    "\n",
    "    labels = watershed(-distance_map, markers)#, mask=maskSobel)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i7Itsh76KGy_"
   },
   "outputs": [],
   "source": [
    "def findContours(gray, mode=3, returnContours=False):\n",
    "\n",
    "    markers = findMarkers(gray)\n",
    "    if np.all(np.count_nonzero(markers==255)<100000):\n",
    "        raise NoMarkersError\n",
    "    maskSobel = getSobel(gray)\n",
    "    # Iterate through unique labels\n",
    "    labels = doWatershed(markers, maskSobel)\n",
    "    \n",
    "    black=np.zeros(gray.shape, np.uint8)\n",
    "\n",
    "    n = 0\n",
    "    Areas = []\n",
    "    contours = []\n",
    "    for label in np.unique(labels):\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # Create a mask\n",
    "        mask = np.zeros(markers.shape, dtype=\"uint8\")\n",
    "        mask[labels == label] = 255\n",
    "        # Find contours and determine contour area\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        contours.append(c)\n",
    "        area = cv2.contourArea(c)\n",
    "        if area>10:\n",
    "            Areas.append(area)\n",
    "        n+=1\n",
    "        if mode==0:\n",
    "            cv2.drawContours(black,[c],-1,(255, 255, 255), -1)\n",
    "        if mode==1:\n",
    "            cv2.drawContours(black,[c],-1,(0, 0, 0), 1)\n",
    "        if mode==2:\n",
    "            cv2.drawContours(black,[c],-1,(255, 255, 255), -1)\n",
    "            cv2.drawContours(black,[c],-1,(0, 0, 0), 2)\n",
    "        if mode==3:\n",
    "            cv2.drawContours(gray,[c],-1,(0, 0, 0), 1)\n",
    "    if returnContours:\n",
    "        return contours\n",
    "    else:\n",
    "        return gray, black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawMask(real, contours):\n",
    "    black=np.zeros(real.shape, np.uint8)\n",
    "    black = cv2.cvtColor(black, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.drawContours(black,contours,-1,(255, 255, 255), -1)\n",
    "    cv2.drawContours(black,contours,-1,(0, 0, 0), 3)\n",
    "    return black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ju3jRl7RK0E4"
   },
   "outputs": [],
   "source": [
    "def drawContours(real, contours):\n",
    "    cv2.drawContours(real, contours, -1, (0,200,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(img1, img2):\n",
    "    from skimage.measure import compare_ssim\n",
    "    import imutils\n",
    "    \n",
    "    grayA = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    grayB = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "    (score, diff) = compare_ssim(grayA, grayB, full=True)\n",
    "#     (score, diff) = compare_ssim(img1, img2, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    thresh = cv2.threshold(diff, 220, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))\n",
    "    kernel = np.ones((15,15),np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    cv2.drawContours(thresh,contours,-1,(255, 255, 255), 5)\n",
    "    cv2.drawContours(thresh,contours,-1,(255, 255, 255), -1)\n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST AREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /Users/s70c3/Desktop/rocks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /Users/s70c3/Desktop/rocks/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoMarkersError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('MVI_4106.MOV')\n",
    "f = cap.read()[1]\n",
    "f = cv2.resize(f, (0,0), fx=0.5, fy=0.5)\n",
    "counter = 0\n",
    "while(cap.isOpened() and counter<=500):\n",
    "    try:\n",
    "        frame = cap.read()[1]\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        mask = get_mask(f,frame) \n",
    "        frame1 = frame.copy()\n",
    "        frame, gray = preprocessing(frame)\n",
    "        gray = cv2.bitwise_and(gray, mask)\n",
    "        cnts = findContours(gray, returnContours=True)\n",
    "        black = drawMask(frame1, cnts)\n",
    "        black = cv2.bitwise_and(black, mask)\n",
    "        drawContours(frame1, cnts)\n",
    "        cv2.imwrite(f'/Users/s70c3/Desktop/rocks/img/{counter}.png', frame)\n",
    "        cv2.imwrite(f'/Users/s70c3/Desktop/rocks/contour/{counter}.png', frame1)\n",
    "        cv2.imwrite(f'/Users/s70c3/Desktop/rocks/label/{counter}.png', black)\n",
    "        counter+=1\n",
    "        show(frame1, black)\n",
    "        for _ in range(3):\n",
    "            cap.read()\n",
    "    except NoMarkersError:\n",
    "        print(\"no markers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FindContours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/s70c3/Desktop/90_2_3.mp4')\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    frame, gray = preprocessing(frame)\n",
    "    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,39,2)\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    frame1 = frame.copy()\n",
    "    drawContours(frame1, cnts)\n",
    "    show_two(frame, frame1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Homomorphical filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "# Homomorphic filter class\n",
    "class HomomorphicFilter:\n",
    "    \"\"\"Homomorphic filter implemented with diferents filters and an option to an external filter.\n",
    "    \n",
    "    High-frequency filters implemented:\n",
    "        butterworth\n",
    "        gaussian\n",
    "    Attributes:\n",
    "        a, b: Floats used on emphasis filter:\n",
    "            H = a + b*H\n",
    "        \n",
    "        .\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, a = 0.5, b = 1.5):\n",
    "        self.a = float(a)\n",
    "        self.b = float(b)\n",
    "\n",
    "    # Filters\n",
    "    def __butterworth_filter(self, I_shape, filter_params):\n",
    "        P = I_shape[0]/2\n",
    "        Q = I_shape[1]/2\n",
    "        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n",
    "        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n",
    "        H = 1/(1+(Duv/filter_params[0]**2)**filter_params[1])\n",
    "        return (1 - H)\n",
    "\n",
    "    def __gaussian_filter(self, I_shape, filter_params):\n",
    "        P = I_shape[0]/2\n",
    "        Q = I_shape[1]/2\n",
    "        H = np.zeros(I_shape)\n",
    "        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')\n",
    "        Duv = (((U-P)**2+(V-Q)**2)).astype(float)\n",
    "        H = np.exp((-Duv/(2*(filter_params[0])**2)))\n",
    "        return (1 - H)\n",
    "\n",
    "    # Methods\n",
    "    def __apply_filter(self, I, H):\n",
    "        H = np.fft.fftshift(H)\n",
    "        I_filtered = (self.a + self.b*H)*I\n",
    "        return I_filtered\n",
    "\n",
    "    def filter(self, I, filter_params, filter='butterworth', H = None):\n",
    "        \"\"\"\n",
    "        Method to apply homormophic filter on an image\n",
    "        Attributes:\n",
    "            I: Single channel image\n",
    "            filter_params: Parameters to be used on filters:\n",
    "                butterworth:\n",
    "                    filter_params[0]: Cutoff frequency \n",
    "                    filter_params[1]: Order of filter\n",
    "                gaussian:\n",
    "                    filter_params[0]: Cutoff frequency\n",
    "            filter: Choose of the filter, options:\n",
    "                butterworth\n",
    "                gaussian\n",
    "                external\n",
    "            H: Used to pass external filter\n",
    "        \"\"\"\n",
    "\n",
    "        #  Validating image\n",
    "        if len(I.shape) is not 2:\n",
    "            raise Exception('Improper image')\n",
    "\n",
    "        # Take the image to log domain and then to frequency domain \n",
    "        I_log = np.log1p(np.array(I, dtype=\"float\"))\n",
    "        I_fft = np.fft.fft2(I_log)\n",
    "\n",
    "        # Filters\n",
    "        if filter=='butterworth':\n",
    "            H = self.__butterworth_filter(I_shape = I_fft.shape, filter_params = filter_params)\n",
    "        elif filter=='gaussian':\n",
    "            H = self.__gaussian_filter(I_shape = I_fft.shape, filter_params = filter_params)\n",
    "        elif filter=='external':\n",
    "            print('external')\n",
    "            if len(H.shape) is not 2:\n",
    "                raise Exception('Invalid external filter')\n",
    "        else:\n",
    "            raise Exception('Selected filter not implemented')\n",
    "        \n",
    "        # Apply filter on frequency domain then take the image back to spatial domain\n",
    "        I_fft_filt = self.__apply_filter(I = I_fft, H = H)\n",
    "        I_filt = np.fft.ifft2(I_fft_filt)\n",
    "        I = np.exp(np.real(I_filt))-1\n",
    "        return np.uint8(I)\n",
    "# End of class HomomorphicFilter\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture('/Users/s70c3/Desktop/90_2_3.mp4')\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    frame, gray = preprocessing(frame)\n",
    "    \n",
    "   \n",
    "    show_two(frame, res2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "h63sLlUix19k",
    "XZZAvptc4Er-",
    "p1erpuV2H0jT",
    "q8jTXzhxRi0a",
    "jxgXib62gUNW",
    "C7uldewG-fUT",
    "0RNlgwb6gk-m",
    "q5Wv4yzmg942",
    "LLCTAVOxWlmQ"
   ],
   "name": "StoneAnalysis",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
